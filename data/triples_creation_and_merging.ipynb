{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Creating Triples and merging them for each relation"
      ],
      "metadata": {
        "id": "9yZ-ol7ISKf5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tk1STPwORKHC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "g85ewLUuRov7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the \"adf_with_tfidf.csv\""
      ],
      "metadata": {
        "id": "YqN3YjY8GDnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# adf = pd.read_csv('/content/drive/MyDrive/IIITB Docs/sem2/EduEmbed/EduEmbedd/data_prepare/adf_pc_1.csv')\n",
        "adf = pd.read_csv('/content/drive/MyDrive/IIITB Docs/sem2/EduEmbed/EduEmbedd/data_prepare/adf_with_tfidf.csv')"
      ],
      "metadata": {
        "id": "SnvAQgWARp-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adf"
      ],
      "metadata": {
        "id": "_YIA6qUMRp7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below code creates a DataFrame adf1 which will contain the triples for the \"l_text_topics\" relation along with LDA probability as its weights"
      ],
      "metadata": {
        "id": "p1emHyqTGIRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adf1 = adf[['file_name','l_text_topics']]\n",
        "adf1 = adf1.dropna()\n",
        "adf1 = adf1.melt('file_name')\n",
        "#df15 = df15.drop_duplicates(subset=['topics','variable','value'], keep='last')\n",
        "adf1.rename(columns = {\"file_name\": \"head\"},  \n",
        "          inplace = True) \n",
        "adf1.head(5)\n",
        "print(adf1.shape)\n",
        "\n",
        "adf1['prob'] = adf[['l_text_prob']]\n",
        "adf1.head(50)"
      ],
      "metadata": {
        "id": "UD-fBYxkRp5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adf1['value'] = adf1['value'].apply(lambda x:json.loads(x))\n",
        "adf1['prob'] = adf1['prob'].apply(lambda x:json.loads(x))\n",
        "type(adf1['prob'][0])\n",
        "adf1 = adf1.explode(['value', 'prob'])\n",
        "adf1['value'] = 'topic_' + adf1['value'].astype(str)\n",
        "adf1.head(50)\n"
      ],
      "metadata": {
        "id": "ufTYeu-KRp3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adf1.shape"
      ],
      "metadata": {
        "id": "iJAz4fguRp1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below code creates a DataFrame adf2 which will contain the triples for the \"concept_vocab_index\" relation along with Tf-Idf score as its weights"
      ],
      "metadata": {
        "id": "L7bZR26FGW8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adf2 = adf[['file_name','concept_vocab_index']]\n",
        "adf2 = adf2.dropna()\n",
        "adf2 = adf2.melt('file_name')\n",
        "#df15 = df15.drop_duplicates(subset=['topics','variable','value'], keep='last')\n",
        "adf2.rename(columns = {\"file_name\": \"head\"},  \n",
        "          inplace = True) \n",
        "lst_col = 'value'\n",
        "# adf2 = pd.DataFrame({\n",
        "#     col:np.repeat(adf2[col].values, adf2[lst_col].str.len())\n",
        "#     for col in adf2.columns.difference([lst_col])\n",
        "#     }).assign(**{lst_col:np.concatenate(adf2[lst_col].values)})[adf2.columns.tolist()]\n",
        "\n",
        "\n",
        "adf2['prob'] = adf['concept_vocab_word_tfidf']\n",
        "adf2['prob'] = adf2['prob'].apply(lambda x:ast.literal_eval(x))\n",
        "adf2['value'] = adf2['value'].apply(lambda x:ast.literal_eval(x))\n",
        "adf2.head(50)\n",
        "\n",
        "adf2 = adf2.explode(['value','prob'])\n",
        "adf2 = adf2.drop_duplicates(subset=['head','variable','value','prob'], keep='last')\n",
        "\n",
        "adf2.head(50)\n",
        "\n",
        "# type(adf2['value'][0])"
      ],
      "metadata": {
        "id": "LU1ajeg4RpzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adf2.shape"
      ],
      "metadata": {
        "id": "1Q3e8w_4R37R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below code creates a DataFrame adf3 which will contain the triples for the \"prerequisite\" relation"
      ],
      "metadata": {
        "id": "jJbyZTmIGlpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adf['prerequisite'] = adf['prerequisite'].fillna('start')\n",
        "adf['composite'] = adf['composite'].fillna('end')\n",
        "adf3 = adf[['file_name','prerequisite']]\n",
        "adf3 = adf3.dropna()\n",
        "adf3 = adf3.melt('file_name')\n",
        "#df15 = df15.drop_duplicates(subset=['topics','variable','value'], keep='last')\n",
        "adf3.rename(columns = {\"file_name\": \"head\"},  \n",
        "          inplace = True) \n",
        "\n",
        "adf3 = adf3.drop_duplicates(subset=['head','variable','value'], keep='last')\n",
        "adf3.head()"
      ],
      "metadata": {
        "id": "pFXaCi3aR34i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below code creates a DataFrame adf4 which will contain the triples for the \"level\" relation"
      ],
      "metadata": {
        "id": "L2GlxaL4GyK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adf4 = adf[['file_name']]\n",
        "adf4['variable'] = 'level'\n",
        "adf4['value'] = 'level_1'\n",
        "\n",
        "adf4['value'] = adf4.apply(lambda row: 'level_1' if row['file_name'][6] == '1' else ('level_2' if row['file_name'][6] == '3' else 'level_3'), axis=1)\n",
        "\n",
        "adf4.rename(columns = {\"file_name\": \"head\"},  \n",
        "          inplace = True) \n",
        "# adf4.loc[adf4['file_name'][6] == '2', 'value'] = '3'\n",
        "# adf4.loc[adf4['file_name'][6] == '3', 'value'] = '2'\n",
        "adf4.head()"
      ],
      "metadata": {
        "id": "C0KhzVC6R32o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below code creates a DataFrame adf5 which will contain the triples for the \"concept_vocab_relation\" relation (topics - concept_vocab_index - concept_vocab)"
      ],
      "metadata": {
        "id": "HuJU28azG2Tj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#topics to vacab have to be done separately\n",
        "tw_df1 = pd.read_csv('/content/drive/MyDrive/IIITB Docs/sem2/EduEmbed/EduEmbedd/data_prepare/tw_df1.csv')\n",
        "adf5 = tw_df1[['topic_num','cv_index_1']]\n",
        "adf5 = adf5.dropna()\n",
        "adf5 = adf5.melt('topic_num')\n",
        "#df15 = df15.drop_duplicates(subset=['topics','variable','value'], keep='last')\n",
        "adf5.rename(columns = {\"topic_num\": \"head\"},  \n",
        "          inplace = True) \n",
        "\n",
        "adf5 = adf5.drop_duplicates(subset=['head','variable','value'], keep='last')\n",
        "adf5['head'] = adf5['head'] + 1\n",
        "adf5['head'] = 'topic_' + adf5['head'].astype(str)\n",
        "adf5['variable'] = \"concept_vocab_index\"\n",
        "adf5.head()"
      ],
      "metadata": {
        "id": "-s5liIT_2stP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adf5.shape"
      ],
      "metadata": {
        "id": "VL6aVRZ52sqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are merging all the above created dataframes for different relations and save them as \"triples.csv\" which will be used for training the KGE models"
      ],
      "metadata": {
        "id": "hEoG5PugHWLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fdf = pd.concat([adf1,adf2,adf3,adf4,adf5])\n"
      ],
      "metadata": {
        "id": "3hjK4GtxR30v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assigning the default weights to the remainging relations where weight value is not defined\n"
      ],
      "metadata": {
        "id": "hneuuep6HnfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fdf = fdf.fillna(1)\n",
        "fdf"
      ],
      "metadata": {
        "id": "Fsz4lZ09R3y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fdf.to_csv('triples.csv')"
      ],
      "metadata": {
        "id": "imVX6oUJR3w6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6eoeWtXBR3uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YLTdqmzdR3s1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}